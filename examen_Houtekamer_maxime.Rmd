---
title: "Statistics Examen_NeuroBIM"
author: "Maxime Houtekamer"
date: "16 november 2015"
output: pdf_document
---
#Loading the data file into R
First of all, the data was loaded into R from the textfile. A summary of the data was obtained as an indication whether the data was correctly loaded into R.
```{r loading datafile, echo=FALSE}
data<-read.table("lesionsBIM.txt",header=TRUE)
data1<-read.table("lesionsBIM.txt",header=TRUE)
```

#Let's add a collumn for the difference between time needed
```{r learning, echo=FALSE}
diff<-vector()
for(i in 1:(length(data[,1]))){
  if(as.character(data[i,1]) == "D5 "){
    diff<-c(diff,(data[i,22] - data[i,26]))
      } else if(as.character(data[i,1]) == "D3 "){
    diff<-c(diff,(data[i,22] - data[i,24]))
    }
}
data<-cbind(data,diff)
```

#Creating seperate files for the 4 conditions
The mice were either trained in 3 sessions (D3) or in 5 sessions (D5). Within each of these two groups, the animals were either lesioned in the dorsal hippocampus (H) or they were given a sham lesion (SH). These groups were originally stored in the datafile, but will now be sorted in order to easily be able to display them seperately.
```{r seperate data , echo=FALSE}
d3<-data[1:48,]
d5<-data[49:90,]
d3sh<-data[49:72,]
d5sh<-data[73:90,]
d3h<-data[25:48,]
d5h<-data[1:24,]

``` 

#Learning time
The mice were given a task, and the time they spent in the dark is a measure of how well they learnt it.


```{r learning time plots, echo=FALSE}
par(mfrow=c(2,3))
boxplot(d5[22:26],ylim=c(0, 60))
title(main="D5")
boxplot(d5h[22:26],ylim=c(0, 60))
title(main="D5 + lesion")
boxplot(d5sh[22:26],ylim=c(0, 60))
title(main="D5 + sham lesion")
boxplot(d3[22:24],ylim=c(0, 60))
title(main="D3")
boxplot(d3h[22:24],ylim=c(0, 60))
title(main="D3 + lesion")
boxplot(d3sh[22:24],ylim=c(0, 60))
title(main="D3 + sham lesion")
```

```{r learning means, echo=FALSE}
mean(d5h[,27])
mean(d5sh[,27])
mean(d3h[,27])
mean(d3sh[,27])

```

#Is the data normally distributed?

First, Let's look at histograms of each group.

```{r normal distribution of learning, echo=FALSE}

par(mfrow=c(2,2))
hist(d5h[,27])
hist(d5sh[,27])
hist(d3h[,27])
hist(d3sh[,27])

```

#NORMAL DISTIBUTION?
We will carry out the shapiro-Wilk test. If p>a (bigger than 0.05 generally), the data is normal.
```{r shapiro test, echo=FALSE}
shapiro.test(d5h[,27])
shapiro.test(d5sh[,27])
shapiro.test(d3h[,27])
shapiro.test(d3sh[,27])
```
All the values are higher than p=0.05, so the data is normally distributed.

#Making a new dataframe for ANOVA
We will make a list of the factors (d5h, d5sh, d3h, d3sh), and a list with the "learned" decrease in time needed to explore the matrix.
```{r dataframe creation, echo=FALSE}
factorlist<-c((rep("d5h",24)),(rep("d5sh",18)),(rep("d3h",24)),(rep("d3sh",24)))
variablelist<-c(d5h[,27],d5sh[,27],d3h[,27],d3sh[,27])
d1<-data.frame(factorlist,variablelist)
colnames(d1)<-c("exp","values")
f1<-d1$values~d1$exp
```

#Homogeneity of Variance
```{r bartlett, echo=FALSE}
bartlett.test(f1)
```

#ANOVA
Maybe we should instead to a repeated measures anova where we follow the animal over the different learning trials.
```{r ANOVA, echo=FALSE}
aov1<-aov(f1)
summary(aov1)
```
The anova is highly significant at p<0.05. Let's do a post-hoc Tukey test to find where the differences are
#Tukey posthoc
```{r Tukey, echo=FALSE}
t1<-TukeyHSD(aov1)
t1
plot(t1)
```
#Repeated measures ANOVA
```{r RANOVA, echo=FALSE}
id<-vector()
for(i in 1:42){
  id<-c(id,(rep(i,5)))
  }
for(i in 43:90){
  id<-c(id,(rep(i,3)))
  }


group<-c((rep("d5h",(24*5))),(rep("d5sh",(18*5))),(rep("d3h",(24*3))),(rep("d3sh",(24*3))))



tasktime<-vector()
for(i in 1:24){
     tasktime<-c(tasktime,data1[i,22])
     tasktime<-c(tasktime,data1[i,23])
     tasktime<-c(tasktime,data1[i,24])
     tasktime<-c(tasktime,data1[i,25])
     tasktime<-c(tasktime,data1[i,26])
  }
for(i in 73:90){
    tasktime<-c(tasktime,data1[i,22])
    tasktime<-c(tasktime,data1[i,23])
    tasktime<-c(tasktime,data1[i,24])
    tasktime<-c(tasktime,data1[i,25])
    tasktime<-c(tasktime,data1[i,26])
  }
for(i in 25:72){
      tasktime<-c(tasktime,data1[i,22])
      tasktime<-c(tasktime,data1[i,23])
      tasktime<-c(tasktime,data1[i,24])
  }

time<-c(rep(1:5,(42)),rep(1:3,(48)))

d2<-data.frame(id,group,tasktime,time)


##convert variables to factor
d2<-within(d2, {
  group<-factor(group)
  time<-factor(time)
  id<-factor(id)
})
par(cex = .6)

with(d2,interaction.plot(time, group, tasktime,
                         ylim= c(0,50), lty=c(1,20,1,20),col = c(3,2,"darkgreen","darkred"),
                         ylab= "Time needed to complete task", xlab= "Trial",trace.label="Group",main="Interaction plot of learning"))

d2.aov<-aov(tasktime ~ group * time + Error(id), data=d2)
summary(d2.aov)
```

```{r contrasts, echo=FALSE}
library(afex)
library(multcomp)
library(lattice)

```



model.cs <- gls(tasktime ~ group * time , data = d2,
  corr = corCompSymm(, form = ~ 1 | id) )

summary(model.cs)

The between group tests indicates that the variable group is significant. consequently, int he graph we see that the liens for the two groups are rather far apart. The within subject test indicates that there is a significant time effect, inother words, the groups do change other time, both groups are taking less time to complete the task over time. Morover, the interaction of time and group is significant which means that the groups are changing over time but are changing in different ways, which means that in the graph, the liens will not be parallel.

```{r RANOVA 2, echo=FALSE}
dvm<-data.frame()
dvm<-cbind(data[,22:26],c((rep("d5h",24)),(rep("d3h",24)),(rep("d3sh",24)),(rep("d5sh",18))))
colnames(dvm)<-c("D1","D2","D3","D4","D5","group")

#maxime out
```

#DAY 1
```{r posthoc contrasts with a t test 1, echo=FALSE}
factorlistD1<-c((rep("d5h",24)),(rep("d5sh",18)),(rep("d3h",24)),(rep("d3sh",24)))
variablelistD1<-c(d5h[,22],d5sh[,22],d3h[,22],d3sh[,22])
D1<-data.frame(factorlistD1,variablelistD1)
colnames(D1)<-c("exp","values")
fD1<-D1$values~D1$exp
aovD1<-aov(fD1)
summary(aovD1)
tD1<-TukeyHSD(aovD1)
tD1
plot(tD1)
```

#DAY 2
```{r posthoc contrasts with a t test 2, echo=FALSE}
factorlistD2<-c((rep("d5h",24)),(rep("d5sh",18)),(rep("d3h",24)),(rep("d3sh",24)))
variablelistD2<-c(d5h[,23],d5sh[,23],d3h[,23],d3sh[,23])
D2<-data.frame(factorlistD2,variablelistD2)
colnames(D2)<-c("exp","values")
fD2<-D2$values~D2$exp
aovD2<-aov(fD2)
summary(aovD2)
tD2<-TukeyHSD(aovD2)
tD2
plot(tD2)
```
#DAY 3
```{r posthoc contrasts with a t test 3, echo=FALSE}
factorlistD3<-c((rep("d5h",24)),(rep("d5sh",18)),(rep("d3h",24)),(rep("d3sh",24)))
variablelistD3<-c(d5h[,24],d5sh[,24],d3h[,24],d3sh[,24])
D3<-data.frame(factorlistD3,variablelistD3)
colnames(D3)<-c("exp","values")
fD3<-D3$values~D3$exp
aovD3<-aov(fD3)
summary(aovD3)
tD3<-TukeyHSD(aovD3)
tD3
plot(tD3)
```
#DAY 4
```{r posthoc contrasts with a t test 4, echo=FALSE}
factorlistD4<-c((rep("d5h",24)),(rep("d5sh",18)))
variablelistD4<-c(d5h[,25],d5sh[,25])
D4<-data.frame(factorlistD4,variablelistD4)
colnames(D4)<-c("exp","values")
fD4<-D4$values~D4$exp
aovD4<-aov(fD4)
summary(aovD4)
tD4<-TukeyHSD(aovD4)
tD4
plot(tD4)
```
#DAY 5
```{r posthoc contrasts with a t test 5, echo=FALSE}
factorlistD5<-c((rep("d5h",24)),(rep("d5sh",18)))
variablelistD5<-c(d5h[,26],d5sh[,26])
D5<-data.frame(factorlistD5,variablelistD5)
colnames(D5)<-c("exp","values")
fD5<-D5$values~D5$exp
aovD5<-aov(fD5)
summary(aovD5)
tD5<-TukeyHSD(aovD5)
tD5
plot(tD5)
```

## Are there structures that are differentially activated depending on the duration of the training?

I think the best option here is MANOVA. 
I used this video first https://www.youtube.com/watch?v=48cZ2cMBpio
```{r manova, echo=FALSE}

manova1<-manova( cbind(STLD,STMD,AMBASLAT,AMLAT,ENTORH,PERIRH,CA1,CA3,DG,CINGULAR,PRELIMB,SOMSENS,SUBICULUM,ACCCORE,ACCSHELL,VISUAL,PIRIFORM,PARIETAL,RETROSPLEN)~as.factor(TRAIN),data=data1)
summary(manova1)
```

I don't think these results are helpful at all. So there are areas that differ.. ok..


## What are the structure activities that are correlated with performance (in the last training session) ?

Ok. So we need a correlation. then we need a matrix.

```{r corrmatrix, echo=FALSE}
library(Hmisc)
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

cordata<-cbind(data1[,3:21],data1[,24],data1[,26])
final<-c(data1[c(1:24,73:90),26],data1[c(25:72),24])
pooledcordata<-cbind(data1[,3:21],final)
cordataD5H<-cordata[1:24,c(1:6,10:19,21)]
cordataD3H<-cordata[25:48,1:20]
cordataD5SH<-cordata[73:90,c(1:19,21)]
cordataD3SH<-cordata[49:72,1:20]

resp<-rcorr(as.matrix(pooledcordata))
matrixp<-flattenCorrMatrix(resp$r, resp$P)
print(matrixp[172:190,])

res1<-rcorr(as.matrix(cordataD5H))
matrix1<-flattenCorrMatrix(res1$r, res1$P)
print(matrix1[121:136,])

res2<-rcorr(as.matrix(cordataD3H))
matrix2<-flattenCorrMatrix(res2$r, res2$P)
print(matrix2[172:190,])

res3<-rcorr(as.matrix(cordataD3SH))
matrix3<-flattenCorrMatrix(res3$r, res3$P)
print(matrix3[172:190,])

res4<-rcorr(as.matrix(cordataD5SH))
matrix4<-flattenCorrMatrix(res4$r, res4$P)
print(matrix4[172:190,])
```

First took all the data to see whether they are normally distributed or not:
per brain area per group
4 groups, 
lesion vs. non lesion
depending on normality: t test or wilcox



#NORMAL DISTIBUTION?
We will carry out the shapiro-Wilk test. If p>a (bigger than 0.05 generally), the data is normal.
```{r shapiro tests, echo=FALSE, results="hide"}
d5hc<-d5h[,c(1:8,12:26)]
for(i in 3:18){
  print(i)
  print(shapiro.test(d5hc[,i]))
}
for(i in 3:21){
  print(i)
  print(shapiro.test(d5sh[,i]))
}
d3hc<-d3h[,c(1:8,12:26)]
for(i in 3:18){
  print(i)
  print(shapiro.test(d3hc[,i]))
}
for(i in 3:21){
  print(i)
  print(shapiro.test(d3sh[,i]))
}

```
d5h[,c(3,17,20,21)] are not normally distributed
d5sh[,c(3)] is not normally distributed
d3h[,c(15,21)] are not normally distributed
d3sh[,c(3,8,2,14,16,18)] is not normally distributed.
You have a small sample size but the population is actually normally distributed, so we will use a parametric test anyway

# ok fuck this shit let's do a t test for all these fuckers

t.test(collumn 1, collumn 2)
 skip collumns 9:11 for d3h vs d5h
```{r fucking t test}
for(i in c(3:8,12:21)){
  print(t.test(d3h[,i],d5h[,i]))
}  
for(i in c(3:21)){
  print(t.test(d3sh[,i],d5sh[,i]))
}
```
##FIGURETIME.

```{r figures, echo=FALSE}
meand3h<-vector()
meand5h<-vector()
meand3sh<-vector()
meand5sh<-vector()
for(i in c(3:8,12:21)){
  x<-mean(d3h[,i])
  meand3h<-c(meand3h,x)
} 
for(i in c(3:8,12:21)){
  x<-mean(d5h[,i])
  meand5h<-c(meand5h,x)
}
for(i in c(3:21)){
  x<-mean(d3sh[,i])
  meand3sh<-c(meand3sh,x)
}
for(i in c(3:21)){
  x<-mean(d5sh[,i])
  meand5sh<-c(meand5sh,x)
}

library(ggplot2)
library(reshape)
```



```{r plotblock, echo=FALSE}
whut = c("STLD","STMD","AMBASLAT","AMLAT","ENTORH","PERIRH","CINGULAR","PRELIMB","SOMSENS","SUBICULUM","ACCCORE","ACCSHELL","VISUAL","PIRIFORM","PARIETAL","RETROSPLEN")
dumb<-c(1:16)
x<-data.frame(whut,dumb)
x$whut<-factor(x$whut, levels=x$whut)
Three_day_training = meand3h
Five_day_training = meand5h
label.df <- data.frame(Group = c("CINGULAR","PARIETAL"),
                       Value = c(1741.819,993.603))

to_plot <- data.frame(x=x$whut,y1=Three_day_training,y2=Five_day_training)

melted<-melt(to_plot, id="x")

p<-ggplot(melted,aes(x=x,y=value,fill=variable))+ theme_bw() + scale_fill_manual(values=c("#999999","484848" ),name="Experimental\nCondition", breaks=c("y1", "y2"),labels=c("Three day training", "Five day training")) + theme(axis.text.x = element_text(angle = 90, hjust = 1))  + labs(title = "Activation of Brain Areas\nAfter Training and Lesion") + labs(y = "Level of Activation")+ labs(x="Brain area") + geom_bar(stat="identity", alpha=1)

print(p)
```

```{r plotblock 2,echo=FALSE}
whut <- c("STLD","STMD","AMBASLAT","AMLAT","ENTORH","PERIRH","CA1","CA2","DG","CINGULAR","PRELIMB","SOMSENS","SUBICULUM","ACCCORE","ACCSHELL","VISUAL","PIRIFORM","PARIETAL","RETROSPLEN")
dumb<-c(1:19)
x<-data.frame(whut,dumb)
x$whut<-factor(x$whut, levels=x$whut)
Three_day_training = meand3sh
Five_day_training = meand5sh
label.df <- data.frame(Group = c("CINGULAR","PARIETAL"),
                       Value = c(1741.819,993.603))

to_plot <- data.frame(x=x$whut,y1=Three_day_training,y2=Five_day_training)

melted<-melt(to_plot, id="x")

p<-ggplot(melted,aes(x=x,y=value,fill=variable))+ theme_bw() + scale_fill_manual(values=c("#999999","484848" ),name="Experimental\nCondition", breaks=c("y1", "y2"),labels=c("Three day training", "Five day training")) + theme(axis.text.x = element_text(angle = 90, hjust = 1))  + labs(title = "Activation of Brain Areas After Training") + labs(y = "Level of Activation")+ labs(x="Brain area") + geom_bar(stat="identity", alpha=1)

print(p)
```
